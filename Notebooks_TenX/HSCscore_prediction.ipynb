{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HSC score prediction\n",
    "## Xiaonan Wang\n",
    "## 30Apr2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xw251/miniconda3/envs/scanpy_py368/lib/python3.6/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version.  The public classes are available in the top-level namespace.\n",
      "  from pandas.core.index import RangeIndex\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sklearn\n",
    "import platform\n",
    "import scanpy as sc\n",
    "sc.settings.verbosity = 3  # verbosity: errors (0), warnings (1), info (2), hints (3)\n",
    "sc.logging.print_versions()\n",
    "sc.settings.set_figure_params(dpi=80, color_map='viridis', vector_friendly=False,  dpi_save=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read('./write/Patel_raw_afterQC.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_count_normalise(count_matrix):\n",
    "    \"\"\"Normalise count matrix for input into hscScore model.\n",
    "    Performs read depth normalisation normalising each cell so that normalised \n",
    "    counts sum to the same value.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    count_matrix : pandas dataframe\n",
    "        Gene count matrix of dimension cells x genes with column names as genes\n",
    "        and index as cell names\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    **norm_matrix** : pandas dataframe\n",
    "        Normalised count matrix of dimension cells x genes\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set the value normalised counts will sum to for each cell\n",
    "    wilson_molo_genes_median_counts = 18704.5\n",
    "    \n",
    "    # Scale rows\n",
    "    count_matrix_expression = np.array(count_matrix, dtype='float')\n",
    "    counts_per_cell = np.sum(count_matrix_expression, axis=1)\n",
    "    counts_per_cell += (counts_per_cell == 0)\n",
    "    counts_per_cell /= wilson_molo_genes_median_counts\n",
    "    norm_matrix_expression =  count_matrix_expression/counts_per_cell[:, None]\n",
    "    norm_matrix = pd.DataFrame(norm_matrix_expression, index=count_matrix.index,\n",
    "                               columns=count_matrix.columns)\n",
    "    # log + 1 transform the data\n",
    "    norm_matrix = np.log(norm_matrix + 1)\n",
    "    \n",
    "    return norm_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xw251/miniconda3/envs/scanpy_py368/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.preprocessing.data module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.preprocessing. Anything that cannot be imported from sklearn.preprocessing is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/xw251/miniconda3/envs/scanpy_py368/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 0.21.2 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/xw251/miniconda3/envs/scanpy_py368/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neural_network.multilayer_perceptron module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neural_network. Anything that cannot be imported from sklearn.neural_network is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/xw251/miniconda3/envs/scanpy_py368/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MLPRegressor from version 0.21.2 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/xw251/miniconda3/envs/scanpy_py368/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.21.2 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# read in what's required for the model prediction, the model and the list of genes that used to train the model\n",
    "hsc_score = pickle.load(open('/home/xw251/rds/rds-bg200-hphi-gottgens//users/xw251/Files/HSCscore_files/' + 'hscScore_model.pkl', 'rb'))\n",
    "model_genes = np.genfromtxt('/home/xw251/rds/rds-bg200-hphi-gottgens//users/xw251/Files/HSCscore_files/' + 'model_molo_genes.txt', dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n",
      "19806\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "print(len(model_genes))\n",
    "print(len(adata.var_names))\n",
    "print(len(np.intersect1d(model_genes, adata.var_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLgenes = np.intersect1d(model_genes, adata.var_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_sub = adata[:,OLgenes].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_data_molo = pd.DataFrame(adata_sub.X.todense(), index=adata_sub.obs_names, columns=adata_sub.var_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24599, 99)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_data_molo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2810417H13Rik' 'Fam64a' 'Sgol1' 'Sqrdl']\n"
     ]
    }
   ],
   "source": [
    "# add in the empty genes\n",
    "missingGenes = np.setdiff1d(model_genes, adata.var_names)\n",
    "print(missingGenes)\n",
    "for g in missingGenes:\n",
    "    count_data_molo[g] = [0]*count_data_molo.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_data_molo = count_data_molo.loc[:,model_genes].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24599, 103)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_data_molo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_data_molo = total_count_normalise(count_data_molo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_hsc_scores = hsc_score.predict(np.array(normalised_data_molo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.06468229,  0.01055192,  0.05370454, ..., -0.00708   ,\n",
       "        0.01739389,  0.03743835])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_hsc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(predicted_hsc_scores, index=adata.obs_names).to_csv('HSCscore_pred.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
